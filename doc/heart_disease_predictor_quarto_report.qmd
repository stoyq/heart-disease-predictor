---
title: Heart Disease Prediction Model
author: "Johnson Chuang | Eduardo Sanches | Azadeh Ramesh | Jose Davila"
date: "2025/12/04"
jupyter: python3
format: 
    html:
        toc: true
        toc-depth: 2
        theme: cosmo
    pdf:
        toc: true
        toc-depth: 2
bibliography: references.bib
execute:
  echo: false
  warning: false
editor: source
---

# Summary

Heart disease is one of the leading causes of death globally, and early detection is critical for prevention and treatment (@detrano1989cad). In this project, we use the UCI Heart Disease (@uci_heart_disease) dataset to build a machine-learning model that predicts whether a patient is likely to have heart disease based on clinical and physiological attributes. We load the dataset directly from the web, clean and wrangle the data, perform exploratory data analysis (EDA), and train a classification model (SVC) to identify important predictors of heart disease. Our results highlight key risk indicators that align with well-known medical knowledge, demonstrating how machine learning can support early screening and clinical decision-making.

# Introduction

The objective of this project is to develop a predictive model that determines whether a patient is at risk of heart disease using a set of clinical measurements. Heart disease diagnoses often rely on many interacting factors such as chest pain symptoms, blood pressure, cholesterol levels, and exercise response. Machine-learning models can help uncover patterns in these variables and support early identification of high-risk patients.

Our research question is:

“Given a patient’s clinical and physiological attributes, can we accurately predict whether they have heart disease?”

To answer this question, we use the publicly available Heart Disease dataset from the UCI Machine Learning Repository. This dataset contains multiple medically relevant variables, making it suitable for a classification model such as a SVC.

# Dataset Description

We use the Heart Disease dataset from the UCI Machine Learning Repository, a widely used benchmark dataset for medical prediction tasks. The dataset includes the following 14 attributes:

- Age
- Sex
- Chest Pain Type (cp)
- Resting Blood Pressure (trestbps)
- Cholesterol (chol)
- Fasting Blood Sugar (fbs)
- Resting ECG results (restecg)
- Maximum heart rate achieved (thalach)
- Exercise induced angina (exang)
- ST depression (oldpeak)
- Slope of ST segment (slope)
- Number of major vessels (ca)
- Thalassemia result (thal)
- num (Target: the predicted attribute (0 = no heart disease, 1 = heart disease))

These variables include both continuous and categorical measurements commonly used in clinical diagnostics.

The following table @tbl-info_stats shows the type of each measurement and the number of null and non-null counts in the dataset.

:::{#tbl-info_stats tbl-cap="Data types of feature names"}
```{python}
import pandas as pd

df = pd.read_csv("../eda/tables/info_stats.csv")
df
```
:::

# Methodology
We build a machine-learning classification model using the UCI Heart Disease dataset:

Load data from the original source on the web: https://archive.ics.uci.edu/dataset/45/heart+disease

Wrangle and clean the data

Replace missing values
Assign meaningful column names
Convert categorical variables to numeric where needed
Ensure that the target variable is binary (0 = no heart disease, 1 = heart disease)
Perform exploratory data analysis (EDA)
Summary statistics for continuous variables
Count plots for categorical variables
Histograms and boxplots to understand feature distributions
Create visualizations relevant to the classification task
Pairplots to explore relationships between key features
Distribution of target classes
Feature correlation matrix
Build a classification model
A SVC model is trained to predict heart disease.
We split the dataset into training and testing subsets and evaluate model accuracy.
Visualize the model results
Plot of the trained SVC model
Feature importance bar chart

# Importing the Dataset

A special note about our data download process: The following code downloads the zip file from UCI's website, unpacks them, and grabs the data of interest (Cleveland data). It is then processed minimally by adding the correct column names, and finally written out as a CSV to the data/processed folder.

In our actual analysis, we fetch the same data directly using UCI's own ucimlrepo library. The data is the same. But we include this part to show how you can download the data without UCI's own library.

# Data Validation

Data validation include ALL the checks you wrote:
- Data Type Check
- Missing Values Check
- Duplicate Check
- Category Level Check
- Logical Ranges Check
- Train/Test Leakage Check

# Exploratory Data Analysis (EDA)


We start by calculating some statistics for all the features:

:::{#tbl-describe_stats tbl-cap="Statistics of features"}
```{python}
import pandas as pd

df = pd.read_csv("../eda/tables/describe_stats.csv")
df
```
:::

Next we look at number of unique values of each feature:

:::{#tbl-unique_stats tbl-cap="Number of unique values per features"}
```{python}
import pandas as pd

df = pd.read_csv("../eda/tables/unique_stats.csv")
df
```
:::

The plots below are distribution of various features color coded by the target value (Disease or No Disease):

![Feature distribution grid plot](../eda/img/feature_distributions_grid.png){#fig-eda}



# Modeling Section

## Column Transformations

The analysis dataset was split into two sets, training and test sets. A 80/20 split was utilized, along with stratification on the target variable, to preserve class proportions across splits. Predictors were grouped into three categories: numerical features (age, trestbps, chol, thalach, oldpeak), categorical features (cp, restecg, slope, ca, thal), and binary  (sex, fbs, exang). A scikit-learn ColumnTransformer was used to apply StandardScaler to the  numerical columns, one-hot encoding to the categorical features,and passs through the binary featuressoo they remain unchanged. These transformations ensured that all features were on appropriate scales and in a numeric format suitable for our SVC model, while keeping all preprocessing steps encapsulated within the modeling pipeline to avoid data leakage.

## Create the Pipeline

The column transformer and the Support Vector Classifier (SVC) were combined into a single pipeline. This way, we ensure that for each resampling split, the preprocessing steps are fit exclusively on the training portion of the dataset and subsequently applied to the validation portion. This design yields a more realistic assessment of model performance and prevents information from the test folds from influencing the training process.

## Crossvalidation

On the training set, we applied a  5-fold cross-validation using the cross_validate function, with both training and validation scores reported for each fold. The results were aggregated to compute the mean and standard deviation across the cross-validation folds, which allows us to generate a summary of the model’s  performance and its variability.


## Fit the Model
After cross-validation, the final SVC pipeline was fit on the full training set. The fitted pipeline was then used to generate predictions on the held-out test set, enabling an out-of-sample evaluation of classification performance.


```{python}
import pandas as pd

df = pd.read_csv("../results/model_classification_report.csv")
df
```

![Coefficients of our model](../results/model_coefficients.png){#fig-coefs}

## Predict (X_test) and compare with Actuals (y_test)

# Discussion

The SVC model was able to identify meaningful patterns to predict heart disease based on the data, with a test score of 0.61 and train score of 0.78. Based on these results, it might indicate that there was some overfitting based on the large difference between training and test results.

From the EDA (@fig-eda), we see that various features such as age, sex, chol and more have clear differences in their distribution between disease and no disease which will help the model to predict between the two. For a better predictor, we may want to incorporate additional features given the complexity of heart disease.

Our final model contain the coefficient values as seen in @fig-coefs.

# Results and Conclusion

Our analysis shows that several clinical features differ noticeably between patients with and without heart disease. As seen in the EDA histograms, patients with heart disease tend to have higher resting blood pressure (trestbps), higher ST-depression values (oldpeak), and lower maximum heart rate achieved (thalach) compared to individuals without disease. After preprocessing the dataset using scaling for numerical variables and one-hot encoding for categorical variables, we trained a Support Vector Classifier (SVC) model. Cross-validation results indicate an average test accuracy of 0.61, with a higher training accuracy of 0.78, suggesting some overfitting. When evaluating predictions on the unseen test set, the model correctly identified many cases but also showed several misclassifications, especially where the model predicted “0” (no disease) but the true label was “1” or “2.” Overall, while the model captures meaningful patterns in the dataset, its moderate predictive performance suggests that further tuning, alternative models, or feature engineering may be needed to improve accuracy and reduce classification bias.


## References